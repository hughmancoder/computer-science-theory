{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import scipy\n",
    "\n",
    "import cvxpy as cp\n",
    "cvxopt_solvers.options['show_progress'] = False\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib\n",
    "from sklearn import svm\n",
    "import plotly.express as px\n",
    "from scipy.sparse import csr_matrix \n",
    "from numpy import linalg as LA\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = [i for i in range(201)]\n",
    "train = pd.read_csv('train.csv', sep = ',', names = col_name)\n",
    "data_test = pd.read_csv('test.csv', sep = ',', names = col_name)\n",
    "data_train = train.iloc[0:4000]\n",
    "validation = train.iloc[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing data frame\n",
    "def describe_data(df):\n",
    "    print(\"statistical information: \")\n",
    "    display(df.describe(include = 'all'))\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f'The number of data duplicates is {duplicates}')\n",
    "    else:\n",
    "        print('There are no duplicates in the data')\n",
    "    print(\"Data contains {0} samples/rows and {1} columns/features\".format(df.shape[0], df.shape[1] - 1))\n",
    "    # print(\"Number of dimensions:\",df.shape[1])\n",
    "\n",
    "describe_data(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "label_train = data_train.values[:,0] # y becomes our labels vector\n",
    "label_train[label_train == 0] = -1 # replacing 0 classes with -1\n",
    "data_train = data_train.values[:, 1:]\n",
    "\n",
    "label_test = data_test.values[:,0] # y becomes our labels vector\n",
    "label_test[label_test == 0] = -1\n",
    "data_test = data_test.values[:, 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_validation = validation.values[:,0] \n",
    "label_validation[label_validation == 0] = -1\n",
    "data_validation = validation.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_train)\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 2\n",
    "Please implement the training and testing algorithms of soft-margin Linear Support Vector Machine from its primal form using CVX\n",
    "\n",
    "By setting C = 100, run your implementation, please report the solution of   and sum of all dimensions of  solution, e.g., np.sum(w). (For a quick check of the correctness of your code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_primal(x , y , c):\n",
    "    # number of samples/vectors and features/dimensions respectively\n",
    "    n, d = x.shape \n",
    "    # 200 by 1 column vector\n",
    "    w = cp.Variable(d) \n",
    "    # offset/bias\n",
    "    b = cp.Variable()\n",
    "    # xi (error/slack) variable for each sample corrects the distance between correct plane and input by placing an offset\n",
    "    xi = cp.Variable(n)\n",
    "    \n",
    "    objective = cp.Minimize(0.5 * cp.square(cp.norm(w)) + (c / n) * cp.sum(xi))\n",
    "    # find individual constraints y_i, x_i and xi_i for y_i(w.T @ x_i + b) >= 1 - xi_i\n",
    "    constraint_1 = [y[i] * (x[i] @ w + b) >= 1 - xi[i] for i in range(n)]\n",
    "    # x_i >= 0\n",
    "    constraint_2 = [xi[i] >= 0 for i in range(n)]\n",
    "    # combining constraints into cvxpy form\n",
    "    constraints = constraint_1 + constraint_2\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    res = problem.solve()\n",
    "    return (w.value, b.value, xi.value)\n",
    "\n",
    "\n",
    "svm_primal_model = svm_train_primal(data_train, label_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_values(svm_model):\n",
    "    w, b, xi = svm_model\n",
    "    # print(w)\n",
    "    print(\"sum of all dimenisions w: \", np.sum(w))    \n",
    "    print(\"primal value of b: \",b)\n",
    "    \n",
    "def svm_predict_primal(x , y , svm_model):\n",
    "    w, b, xi = svm_model\n",
    "    correct_predictions = 0\n",
    "    test_size = x.shape[0]\n",
    "    for i in range(test_size):\n",
    "        y_pred = np.sign(np.dot(x[i], w) + b)\n",
    "        if y_pred == y[i]:\n",
    "            correct_predictions += 1\n",
    "    return correct_predictions / test_size\n",
    "\n",
    "show_values(svm_primal_model)\n",
    "accuracy = svm_predict_primal(data_test, label_test, svm_primal_model)\n",
    "print(\"accuracy of primal form is\", accuracy * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Please implement the training algorithm of the soft-margin Linear Support Vector Machine from its dual form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.15s training time\n",
    "def svm_train_dual (x , y , c):\n",
    "    # samples, dimensions     \n",
    "    n,d = x.shape \n",
    "    y = y.reshape(-1,1) * 1.\n",
    "    X_dash = y * x\n",
    "    # calculate gram matrix H\n",
    "    H = np.dot(X_dash , X_dash.T) * 1.\n",
    "\n",
    "    P = cvxopt_matrix(H)\n",
    "    q = cvxopt_matrix(-np.ones((n, 1)))\n",
    "    G = cvxopt_matrix(np.vstack((np.eye(n)*-1,np.eye(n))))\n",
    "    h = cvxopt_matrix(np.hstack((np.zeros(n), np.ones(n) * c)))\n",
    "    # label vector of size n * 1, cvxopt_matrix(y, (1, n))\n",
    "    A = cvxopt_matrix(y.reshape(1, -1))\n",
    "    # scalar with value zeros\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "\n",
    "    # run solver by matching api\n",
    "    sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x'])\n",
    "    return alphas, y\n",
    "    \n",
    "svm_dual_model = svm_train_dual(data_train, label_train , 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(svm_model):\n",
    "    alphas, y = svm_model\n",
    "    print(alphas.shape)\n",
    "    print(\"sum of all dimenisions alpha: \", np.sum(alphas))    \n",
    "    \n",
    "display_results(svm_dual_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Write code to obtain the primal problem solution w*, b* from its dual solution  alpha*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primal problem solution from dual solution\n",
    "\n",
    "def get_primal_solution_from_dual(x, svm_dual_model):\n",
    "    alphas , y = svm_dual_model\n",
    "    w = ((y * alphas).T @ x).T\n",
    "    b = y - np.dot(x, w)\n",
    "    b = np.mean(b) # take mean bias\n",
    "    return w, b\n",
    "\n",
    "def show(w, b):\n",
    "    print(\"W* \", w)\n",
    "    print(\"b*\", b)\n",
    "    \n",
    "def svm_predict_dual(x, y, w, b):\n",
    "    correct_predictions = 0\n",
    "    test_size = x.shape[0]\n",
    "    for i in range(test_size):\n",
    "        y_pred = np.sign(np.dot(x[i,:], w) + b)\n",
    "        if y_pred == y[i]:\n",
    "            correct_predictions += 1\n",
    "    return correct_predictions / test_size\n",
    "\n",
    "w, b = get_primal_solution_from_dual(data_train, svm_dual_model)\n",
    "dual_accuracy = svm_predict_dual(data_test, label_test, w, b)\n",
    "show(w, b)\n",
    "print(\"dual accuracy is \", dual_accuracy * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Write code to find the support vectors from the primal problem solutions\n",
    "\n",
    "equation form:  y_i = w.T * x_i + b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_test\n",
    "w, b, _ = svm_primal_model\n",
    "# y_pos \n",
    "\n",
    "x = 1 - b * (w)**-1\n",
    "print(x)\n",
    "w.T @ x.T + b >=  1\n",
    "# y_neg\n",
    "w.T @ x.T + b == - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Write code to find the support vectors from the dual problem solutions. Please copy the code snippet for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = linear space\n",
    "x = data_train\n",
    "w, b = get_primal_solution_from_dual(data_train, svm_dual_model)\n",
    "\n",
    "# y_pos \n",
    "w.T * x + b == 1\n",
    "# y_neg\n",
    "w.T * x + b == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Write code to choose C by using the validation set. Please copy the code snippet for the implementation. Report the test accuracy you get by using the optimal C found in the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_fit(x, y, w, b):\n",
    "    test_size = x.shape[0]\n",
    "    correct_predictions = 0\n",
    "    for i in range(test_size):\n",
    "        y_pred = np.sign(np.dot(x[i,:], w.T) + b)\n",
    "        if y_pred == y[i]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    return correct_predictions / test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [2e-10, 2e-8, 2e-6, 2e-4, 2e-2, 2e0, 2e2, 2e4, 2e6,2e7,2e8,2e10]\n",
    "max_accuracy = 0\n",
    "optimal_c = 0\n",
    "\n",
    "# start by taking the first 8 values for now as computation time is too slow;\n",
    "for c in c_values[:6]:\n",
    "    clf = svm.SVC(C = c, kernel = 'linear')\n",
    "    clf.fit(data_validation, label_validation)\n",
    "    w = clf.coef_\n",
    "    b = clf.intercept_\n",
    "    svm_accuracy = test_model_fit(data_train, label_train, w, b)\n",
    "    if svm_accuracy > max_accuracy:\n",
    "        max_accuracy = svm_accuracy\n",
    "        optimal_c = c\n",
    "\n",
    "    print(\"accuracy of scikit learn svm model is\", svm_accuracy * 100, \"% with c value\", c)\n",
    "    \n",
    "print(\"most optimal c is:\", optimal_c)\n",
    "\n",
    "\"\"\"\n",
    "use validation set\n",
    "data_validation\n",
    "label_validation\n",
    "train model\n",
    "get accuracy\n",
    "store most accurate c \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using primal form model\n",
    "for c in c_values[:7]:\n",
    "    svm_primal_model = svm_train_primal(data_train, label_train, 100)\n",
    "    svm_accuracy = test_model_fit(data_train, label_train, w, b)\n",
    "    if svm_accuracy > max_accuracy:\n",
    "        max_accuracy = svm_accuracy\n",
    "        optimal_c = c\n",
    "\n",
    "    print(\"accuracy of scikit learn svm model is\", svm_accuracy * 100, \"% with c value\", c)\n",
    "    \n",
    "print(\"most optimal c is:\", optimal_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_C = 0.0002\n",
    "# optimal_C = 100\n",
    "\n",
    "clf = svm.SVC(C = optimal_C, kernel = 'linear')\n",
    "clf.fit(data_train, label_train) # .fit(x, y)\n",
    "\n",
    "def show(clf):\n",
    "    # print('w = ',clf.coef_)\n",
    "    print('b = ',clf.intercept_)\n",
    "    print('Indices of support vectors = ', clf.support_)\n",
    "    # print(clf.support_.shape)\n",
    "    print('Support vectors = ', clf.support_vectors_)\n",
    "    print('Number of support vectors for each class = ', clf.n_support_)\n",
    "    print('Coefficients of the support vector in the decision function = ', np.abs(clf.dual_coef_))\n",
    "    print(clf.support_vectors_.shape)\n",
    "\n",
    "show(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.coef_\n",
    "b = clf.intercept_\n",
    "svm_accuracy = test_model_fit(data_train, label_train, w, b)\n",
    "print(\"accuracy of scikit learn svm model is\", svm_accuracy * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97e17e3a5115b3201813a983cb4b94900d2052584e97bfd9eeb6cc4985f4f43a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
