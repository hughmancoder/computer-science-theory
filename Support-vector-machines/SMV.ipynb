{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib\\nfrom sklearn import svm\\nimport plotly.express as px\\nfrom scipy.sparse import csr_matrix \\nfrom numpy import linalg as LA\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import scipy\n",
    "\n",
    "import cvxpy as cp\n",
    "cvxopt_solvers.options['show_progress'] = False\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib\n",
    "from sklearn import svm\n",
    "import plotly.express as px\n",
    "from scipy.sparse import csr_matrix \n",
    "from numpy import linalg as LA\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = [i for i in range(201)]\n",
    "train = pd.read_csv('train.csv', sep = ',', names = col_name)\n",
    "data_test = pd.read_csv('test.csv', sep = ',', names = col_name)\n",
    "data_train = train.iloc[0:4000]\n",
    "validation = train.iloc[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistical information: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>-0.027538</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>-0.002810</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-0.00085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.007002</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>-0.005530</td>\n",
       "      <td>0.037802</td>\n",
       "      <td>-0.013870</td>\n",
       "      <td>0.019555</td>\n",
       "      <td>-0.025915</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>0.010985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499952</td>\n",
       "      <td>1.046795</td>\n",
       "      <td>1.055809</td>\n",
       "      <td>1.035735</td>\n",
       "      <td>1.051085</td>\n",
       "      <td>1.059428</td>\n",
       "      <td>1.046060</td>\n",
       "      <td>1.058164</td>\n",
       "      <td>1.057871</td>\n",
       "      <td>1.06592</td>\n",
       "      <td>...</td>\n",
       "      <td>1.045139</td>\n",
       "      <td>1.056644</td>\n",
       "      <td>1.075913</td>\n",
       "      <td>1.045216</td>\n",
       "      <td>1.039436</td>\n",
       "      <td>1.051253</td>\n",
       "      <td>1.071891</td>\n",
       "      <td>1.037967</td>\n",
       "      <td>1.057728</td>\n",
       "      <td>1.047149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.870000</td>\n",
       "      <td>-4.720000</td>\n",
       "      <td>-3.570000</td>\n",
       "      <td>-3.350000</td>\n",
       "      <td>-4.230000</td>\n",
       "      <td>-3.470000</td>\n",
       "      <td>-3.560000</td>\n",
       "      <td>-3.650000</td>\n",
       "      <td>-3.53000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.140000</td>\n",
       "      <td>-4.340000</td>\n",
       "      <td>-4.040000</td>\n",
       "      <td>-3.530000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-3.930000</td>\n",
       "      <td>-3.920000</td>\n",
       "      <td>-3.620000</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>-4.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>-0.740000</td>\n",
       "      <td>-0.670000</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>-0.72000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.660000</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.702500</td>\n",
       "      <td>-0.740000</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>-0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.280000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>3.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>3.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1            2            3            4    \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean      0.510500     0.020805    -0.027538     0.007003    -0.002810   \n",
       "std       0.499952     1.046795     1.055809     1.035735     1.051085   \n",
       "min       0.000000    -3.870000    -4.720000    -3.570000    -3.350000   \n",
       "25%       0.000000    -0.680000    -0.740000    -0.670000    -0.710000   \n",
       "50%       1.000000     0.010000    -0.030000     0.010000     0.010000   \n",
       "75%       1.000000     0.730000     0.672500     0.720000     0.710000   \n",
       "max       1.000000     4.280000     3.510000     3.340000     3.600000   \n",
       "\n",
       "               5            6            7            8           9    ...  \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.00000  ...   \n",
       "mean      0.004585     0.020467     0.004732     0.000155    -0.00085  ...   \n",
       "std       1.059428     1.046060     1.058164     1.057871     1.06592  ...   \n",
       "min      -4.230000    -3.470000    -3.560000    -3.650000    -3.53000  ...   \n",
       "25%      -0.700000    -0.690000    -0.710000    -0.710000    -0.72000  ...   \n",
       "50%       0.020000     0.010000     0.000000    -0.010000     0.00000  ...   \n",
       "75%       0.740000     0.750000     0.730000     0.730000     0.70000  ...   \n",
       "max       3.670000     3.580000     3.500000     4.020000     3.90000  ...   \n",
       "\n",
       "               191          192          193          194          195  \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean     -0.002163    -0.007002     0.015572    -0.005530     0.037802   \n",
       "std       1.045139     1.056644     1.075913     1.045216     1.039436   \n",
       "min      -4.140000    -4.340000    -4.040000    -3.530000    -3.480000   \n",
       "25%      -0.710000    -0.730000    -0.700000    -0.730000    -0.660000   \n",
       "50%      -0.020000    -0.030000     0.020000     0.010000     0.040000   \n",
       "75%       0.700000     0.710000     0.750000     0.720000     0.740000   \n",
       "max       3.950000     3.770000     3.600000     3.760000     3.390000   \n",
       "\n",
       "               196          197          198          199          200  \n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000  \n",
       "mean     -0.013870     0.019555    -0.025915     0.007270     0.010985  \n",
       "std       1.051253     1.071891     1.037967     1.057728     1.047149  \n",
       "min      -3.930000    -3.920000    -3.620000    -4.080000    -4.260000  \n",
       "25%      -0.730000    -0.702500    -0.740000    -0.690000    -0.690000  \n",
       "50%       0.020000     0.030000    -0.015000     0.010000     0.030000  \n",
       "75%       0.710000     0.740000     0.680000     0.710000     0.720000  \n",
       "max       3.330000     4.210000     3.450000     4.050000     3.930000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicates in the data\n",
      "Data contains 4000 samples/rows and 200 columns/features\n"
     ]
    }
   ],
   "source": [
    "# describing data frame\n",
    "def describe_data(df):\n",
    "    print(\"statistical information: \")\n",
    "    display(df.describe(include = 'all'))\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f'The number of data duplicates is {duplicates}')\n",
    "    else:\n",
    "        print('There are no duplicates in the data')\n",
    "    print(\"Data contains {0} samples/rows and {1} columns/features\".format(df.shape[0], df.shape[1] - 1))\n",
    "    # print(\"Number of dimensions:\",df.shape[1])\n",
    "\n",
    "describe_data(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "label_train = data_train.values[:,0] # y becomes our labels vector\n",
    "label_train[label_train == 0] = -1 # replacing 0 classes with -1\n",
    "data_train = data_train.values[:, 1:]\n",
    "\n",
    "label_test = data_test.values[:,0] # y becomes our labels vector\n",
    "label_test[label_test == 0] = -1\n",
    "data_test = data_test.values[:, 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_validation = validation.values[:,0] \n",
    "label_validation[label_validation == 0] = -1\n",
    "data_validation = validation.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.  1. ...  1.  1.  1.]\n",
      "[[-0.36 -0.91 -0.99 ...  0.3   2.44 -1.26]\n",
      " [-1.4  -1.9   0.09 ... -0.2  -0.92 -0.46]\n",
      " [-0.43  1.45 -0.68 ...  0.12  0.01 -0.56]\n",
      " ...\n",
      " [-0.57  0.14 -0.62 ...  0.    0.38 -0.82]\n",
      " [ 0.4   0.16 -0.49 ...  0.89  0.21  1.09]\n",
      " [ 0.86 -0.23 -2.01 ...  0.21  0.68  2.49]]\n"
     ]
    }
   ],
   "source": [
    "print(label_train)\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 2\n",
    "Please implement the training and testing algorithms of soft-margin Linear Support Vector Machine from its primal form using CVX\n",
    "\n",
    "By setting C = 100, run your implementation, please report the solution of   and sum of all dimensions of  solution, e.g., np.sum(w). (For a quick check of the correctness of your code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_primal(x , y , c):\n",
    "    # number of samples/vectors and features/dimensions respectively\n",
    "    n, d = x.shape \n",
    "    # 200 by 1 column vector\n",
    "    w = cp.Variable(d) \n",
    "    # offset/bias\n",
    "    b = cp.Variable()\n",
    "    # xi (error/slack) variable for each sample corrects the distance between correct plane and input by placing an offset\n",
    "    xi = cp.Variable(n)\n",
    "    \n",
    "    objective = cp.Minimize(0.5 * cp.square(cp.norm(w)) + (c / n) * cp.sum(xi))\n",
    "    # find individual constraints y_i, x_i and xi_i for y_i(w.T @ x_i + b) >= 1 - xi_i\n",
    "    constraint_1 = [y[i] * (x[i] @ w + b) >= 1 - xi[i] for i in range(n)]\n",
    "    # x_i >= 0\n",
    "    constraint_2 = [xi[i] >= 0 for i in range(n)]\n",
    "    # combining constraints into cvxpy form\n",
    "    constraints = constraint_1 + constraint_2\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    res = problem.solve()\n",
    "    return (w.value, b.value, xi.value)\n",
    "\n",
    "\n",
    "svm_primal_model = svm_train_primal(data_train, label_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of all dimenisions w:  -0.1452156803361282\n",
      "primal value of b:  1.779813717087077\n",
      "accuracy of primal form is 96.8 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_values(svm_model):\n",
    "    w, b, xi = svm_model\n",
    "    # print(w)\n",
    "    print(\"sum of all dimenisions w: \", np.sum(w))    \n",
    "    print(\"primal value of b: \",b)\n",
    "    \n",
    "def svm_predict_primal(x , y , svm_model):\n",
    "    w, b, xi = svm_model\n",
    "    correct_predictions = 0\n",
    "    test_size = x.shape[0]\n",
    "    for i in range(test_size):\n",
    "        y_pred = np.sign(np.dot(x[i], w) + b)\n",
    "        if y_pred == y[i]:\n",
    "            correct_predictions += 1\n",
    "    return correct_predictions / test_size\n",
    "\n",
    "show_values(svm_primal_model)\n",
    "accuracy = svm_predict_primal(data_test, label_test, svm_primal_model)\n",
    "print(\"accuracy of primal form is\", accuracy * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Please implement the training algorithm of the soft-margin Linear Support Vector Machine from its dual form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.15s training time\n",
    "def svm_train_dual (x , y , c):\n",
    "    # samples, dimensions     \n",
    "    n,d = x.shape \n",
    "    y = y.reshape(-1,1) * 1.\n",
    "    X_dash = y * x\n",
    "    # calculate gram matrix H\n",
    "    H = np.dot(X_dash , X_dash.T) * 1.\n",
    "\n",
    "    P = cvxopt_matrix(H)\n",
    "    q = cvxopt_matrix(-np.ones((n, 1)))\n",
    "    G = cvxopt_matrix(np.vstack((np.eye(n)*-1,np.eye(n))))\n",
    "    h = cvxopt_matrix(np.hstack((np.zeros(n), np.ones(n) * c)))\n",
    "    # label vector of size n * 1, cvxopt_matrix(y, (1, n))\n",
    "    A = cvxopt_matrix(y.reshape(1, -1))\n",
    "    # scalar with value zeros\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "\n",
    "    # run solver by matching api\n",
    "    sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x'])\n",
    "    return alphas, y\n",
    "    \n",
    "svm_dual_model = svm_train_dual(data_train, label_train , 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1)\n",
      "sum of all dimenisions alpha:  19795.781131147898\n"
     ]
    }
   ],
   "source": [
    "def display_results(svm_model):\n",
    "    alphas, y = svm_model\n",
    "    print(alphas.shape)\n",
    "    print(\"sum of all dimenisions alpha: \", np.sum(alphas))    \n",
    "    \n",
    "display_results(svm_dual_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Write code to obtain the primal problem solution w*, b* from its dual solution  alpha*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W*  [[ 1.36058445e-02]\n",
      " [-1.44494765e-01]\n",
      " [ 1.05602137e-01]\n",
      " [-1.01375042e-01]\n",
      " [ 1.60645124e-01]\n",
      " [-9.44365974e-02]\n",
      " [ 3.13664183e-02]\n",
      " [-1.27152307e-01]\n",
      " [ 1.43289557e-01]\n",
      " [ 2.59378428e-02]\n",
      " [ 2.05438001e-01]\n",
      " [ 1.39052047e-01]\n",
      " [-3.03939044e-02]\n",
      " [ 2.37242455e-01]\n",
      " [ 4.57591535e-03]\n",
      " [-1.58526876e-01]\n",
      " [-9.39414348e-02]\n",
      " [-9.76228613e-02]\n",
      " [-1.62307260e-01]\n",
      " [-9.40157756e-03]\n",
      " [ 6.42996647e-02]\n",
      " [ 1.60244533e-01]\n",
      " [ 1.15185126e-01]\n",
      " [-1.72891231e-02]\n",
      " [ 2.80434572e-02]\n",
      " [-8.10259517e-03]\n",
      " [-3.83024322e-03]\n",
      " [-5.72639351e-02]\n",
      " [-1.86879671e-01]\n",
      " [ 2.78171399e-01]\n",
      " [-9.10794539e-02]\n",
      " [-3.97619445e-02]\n",
      " [ 5.12808666e-02]\n",
      " [-1.64046621e-02]\n",
      " [ 1.98490167e-01]\n",
      " [-9.07271378e-02]\n",
      " [ 2.77654401e-02]\n",
      " [-1.13844387e-01]\n",
      " [ 1.54520656e-01]\n",
      " [-7.35715359e-02]\n",
      " [ 1.15954669e-02]\n",
      " [ 3.95013205e-02]\n",
      " [-1.61612940e-01]\n",
      " [-5.33783557e-03]\n",
      " [ 1.98252827e-02]\n",
      " [-4.62452243e-02]\n",
      " [ 2.47505618e-01]\n",
      " [ 7.97978534e-02]\n",
      " [ 1.72144634e-01]\n",
      " [ 1.94782877e-01]\n",
      " [-1.27425423e-01]\n",
      " [-3.64906470e-02]\n",
      " [ 6.86341579e-02]\n",
      " [-1.20439662e-01]\n",
      " [ 7.10000393e-02]\n",
      " [ 5.25466713e-03]\n",
      " [-8.29845894e-02]\n",
      " [ 1.51540117e-01]\n",
      " [-3.39121674e-02]\n",
      " [ 1.21038976e+00]\n",
      " [ 7.17940271e-03]\n",
      " [-8.60635176e-02]\n",
      " [ 4.21901336e-02]\n",
      " [ 5.81465685e-02]\n",
      " [ 3.15879780e-02]\n",
      " [-9.07002460e-02]\n",
      " [ 3.87435875e-03]\n",
      " [ 4.57286972e-02]\n",
      " [-7.64258216e-02]\n",
      " [-1.11904887e-01]\n",
      " [-1.20172222e-01]\n",
      " [-7.48958355e-02]\n",
      " [-6.08039382e-02]\n",
      " [ 1.27737284e-01]\n",
      " [ 1.12994163e-01]\n",
      " [ 9.66244645e-02]\n",
      " [-7.90275466e-02]\n",
      " [-2.74620538e-01]\n",
      " [ 8.38360571e-02]\n",
      " [ 1.59188630e-01]\n",
      " [ 6.83552186e-02]\n",
      " [-1.69127717e-02]\n",
      " [-4.81004940e-02]\n",
      " [ 1.49914911e-01]\n",
      " [ 9.50052416e-02]\n",
      " [-4.82099637e-02]\n",
      " [-4.98277809e-02]\n",
      " [ 5.16385357e-02]\n",
      " [ 8.95497679e-02]\n",
      " [-8.25534614e-01]\n",
      " [ 4.32722575e-02]\n",
      " [ 1.74824178e-01]\n",
      " [-4.16056042e-02]\n",
      " [-8.61064772e-02]\n",
      " [-2.62953565e-03]\n",
      " [-8.12726662e-02]\n",
      " [-4.87644995e-02]\n",
      " [-1.23702809e-01]\n",
      " [ 3.54500035e-02]\n",
      " [-1.43876585e-01]\n",
      " [ 7.82936834e-02]\n",
      " [ 1.43218630e-01]\n",
      " [-5.50021535e-02]\n",
      " [-1.56164368e-01]\n",
      " [ 1.07775188e-01]\n",
      " [-8.90357332e-02]\n",
      " [-2.11157897e-03]\n",
      " [-1.14892943e-01]\n",
      " [-9.85797444e-01]\n",
      " [-1.39065190e-01]\n",
      " [ 1.57259190e-01]\n",
      " [-1.72351701e-02]\n",
      " [-5.58664915e-02]\n",
      " [-9.26479700e-02]\n",
      " [ 8.89621562e-02]\n",
      " [ 1.37331888e-01]\n",
      " [-4.78653313e-02]\n",
      " [-1.42369838e-01]\n",
      " [-2.51110716e-02]\n",
      " [ 3.43352690e-02]\n",
      " [ 2.05268728e-01]\n",
      " [-1.32598241e-01]\n",
      " [-1.47045554e-02]\n",
      " [ 1.92401020e-01]\n",
      " [-1.30652740e-01]\n",
      " [ 7.70707566e-02]\n",
      " [ 1.15660658e-01]\n",
      " [-5.67113073e-02]\n",
      " [ 6.90694968e-02]\n",
      " [ 8.01513152e-04]\n",
      " [ 7.71206727e-02]\n",
      " [-4.99252709e-02]\n",
      " [ 1.61395681e-02]\n",
      " [-4.07550142e-02]\n",
      " [-6.25487917e-02]\n",
      " [-1.89710553e-02]\n",
      " [ 9.12149334e-02]\n",
      " [ 1.04860625e-01]\n",
      " [ 6.32827063e-02]\n",
      " [-2.78051197e-02]\n",
      " [-9.74625212e-03]\n",
      " [-1.95337879e-01]\n",
      " [ 2.52212428e-02]\n",
      " [ 9.16362973e-02]\n",
      " [-2.27842210e-02]\n",
      " [ 1.79891646e-02]\n",
      " [ 6.08844233e-02]\n",
      " [ 9.55114155e-02]\n",
      " [ 6.31174299e-02]\n",
      " [ 2.18680798e-02]\n",
      " [-6.49059157e-04]\n",
      " [ 8.75542085e-02]\n",
      " [-4.55568946e-02]\n",
      " [-1.46843542e-01]\n",
      " [-1.06519437e-01]\n",
      " [-7.07481013e-01]\n",
      " [ 1.11104704e-01]\n",
      " [ 2.30031559e-01]\n",
      " [ 1.84475827e-01]\n",
      " [-5.66793575e-02]\n",
      " [ 4.51125884e-02]\n",
      " [-1.06546804e-01]\n",
      " [-7.09286930e-02]\n",
      " [ 1.14294955e-01]\n",
      " [-3.52886397e-03]\n",
      " [ 1.70848468e-02]\n",
      " [ 9.89909653e-02]\n",
      " [ 7.80088560e-03]\n",
      " [-3.60877022e-02]\n",
      " [-1.77552625e-02]\n",
      " [-9.72248093e-02]\n",
      " [ 8.10173194e-02]\n",
      " [ 7.41482819e-01]\n",
      " [-7.08401336e-03]\n",
      " [ 1.13781052e-01]\n",
      " [-4.41402808e-02]\n",
      " [ 1.32584510e-01]\n",
      " [ 7.38388800e-02]\n",
      " [-6.10061214e-02]\n",
      " [ 4.52057056e-03]\n",
      " [-1.36705254e-02]\n",
      " [ 1.56188815e-02]\n",
      " [-3.00582659e-02]\n",
      " [ 9.19041507e-02]\n",
      " [-2.25892452e-01]\n",
      " [-1.42825578e-01]\n",
      " [-6.07864451e-02]\n",
      " [-1.34500594e-02]\n",
      " [ 6.35919324e-02]\n",
      " [ 2.11330076e-01]\n",
      " [-1.57662808e-01]\n",
      " [-2.39190289e-02]\n",
      " [ 9.42212224e-03]\n",
      " [ 9.13549001e-02]\n",
      " [ 9.49489370e-02]\n",
      " [ 2.28549154e-02]\n",
      " [-5.55078129e-02]\n",
      " [ 1.33887338e-02]\n",
      " [-2.53398912e-01]\n",
      " [ 3.64629268e-02]]\n",
      "b* 3.0990482852929335\n",
      "dual accuracy is  96.13333333333334 %\n"
     ]
    }
   ],
   "source": [
    "# primal problem solution from dual solution\n",
    "\n",
    "def get_primal_solution_from_dual(x, svm_dual_model):\n",
    "    alphas , y = svm_dual_model\n",
    "    w = ((y * alphas).T @ x).T\n",
    "    b = y - np.dot(x, w)\n",
    "    b = np.mean(b) # take mean bias\n",
    "    return w, b\n",
    "\n",
    "def show(w, b):\n",
    "    print(\"W* \", w)\n",
    "    print(\"b*\", b)\n",
    "    \n",
    "def svm_predict_dual(x, y, w, b):\n",
    "    correct_predictions = 0\n",
    "    test_size = x.shape[0]\n",
    "    for i in range(test_size):\n",
    "        y_pred = np.sign(np.dot(x[i,:], w) + b)\n",
    "        if y_pred == y[i]:\n",
    "            correct_predictions += 1\n",
    "    return correct_predictions / test_size\n",
    "\n",
    "w, b = get_primal_solution_from_dual(data_train, svm_dual_model)\n",
    "dual_accuracy = svm_predict_dual(data_test, label_test, w, b)\n",
    "show(w, b)\n",
    "print(\"dual accuracy is \", dual_accuracy * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Write code to find the support vectors from the primal problem solutions\n",
    "\n",
    "equation form:  y_i = w.T * x_i + b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.88654457e+01  1.65891434e+01 -4.15202965e+01  3.50409001e+01\n",
      " -2.25673566e+01  2.38523812e+02 -6.26840489e+01  1.75771985e+02\n",
      " -3.10857546e+02 -1.90217666e+03 -1.74809481e+01 -2.66079046e+01\n",
      " -2.49737514e+01 -2.74994940e+01 -9.64277256e+01  7.53788168e+01\n",
      "  3.18007389e+01  4.04557323e+01  3.32462018e+01  7.00853810e+01\n",
      "  8.39856566e+02 -3.96040384e+01  2.07531698e+02  3.95134849e+01\n",
      "  8.99582297e+01  9.65187673e+01  5.01765978e+02 -1.87868681e+02\n",
      "  2.51244897e+01 -1.44178945e+01  7.60512985e+01  1.30025667e+02\n",
      " -2.82443067e+01  8.49427161e+01 -1.94462324e+01  4.73718674e+01\n",
      " -7.78519843e+01  3.50306813e+01 -3.12836517e+01  4.90379633e+01\n",
      " -6.45054816e+01 -7.72795491e+01  7.64678953e+01  4.36101551e+02\n",
      " -6.38940291e+01  7.30194457e+01 -1.12008012e+01 -2.35055555e+01\n",
      " -1.13910769e+02 -1.70891578e+01  5.73908372e+01 -4.54371377e+01\n",
      " -1.95225342e+01  3.79557690e+01 -3.20717582e+01  4.35525029e+01\n",
      "  3.21572605e+01 -1.74845926e+01  4.92631895e+01 -1.44883250e+00\n",
      " -7.37557336e+01  3.74176457e+01 -5.08175217e+01  1.16388270e+02\n",
      "  3.21915422e+02 -9.41217339e+01  8.68589162e+01  6.17540882e+01\n",
      "  6.54955326e+01  4.51909212e+01  4.02346706e+01  2.70281867e+01\n",
      "  3.32013946e+01 -1.48592947e+01 -4.62182369e+01 -2.76221708e+01\n",
      "  5.05349021e+01  3.47799350e+01 -6.47830077e+01 -4.10004623e+01\n",
      " -4.23781378e+01  7.75140701e+01  1.70276700e+02 -7.01852435e+01\n",
      " -3.57253962e+01  6.76670847e+01  3.07437818e+01 -6.16098269e+01\n",
      " -1.51594691e+02  4.75394137e+00  3.87086358e+02 -2.88899886e+01\n",
      " -5.88842969e+01  5.47713739e+01  5.86381858e+02  4.64646620e+01\n",
      "  9.00774099e+01  5.02837417e+01  7.68626716e+01  3.24846954e+01\n",
      " -6.20885635e+01 -9.11828495e+01  4.67115213e+01  4.30049784e+01\n",
      "  2.99034538e+02  6.31410356e+01 -3.73918400e+02  3.07300829e+01\n",
      "  4.12965694e+00  2.18035283e+01 -6.06544350e+02 -3.22765058e+02\n",
      "  7.83796006e+01  6.95154811e+01 -2.01080896e+01 -2.53927829e+01\n",
      "  3.37601501e+01  3.01246337e+01  4.10959470e+03 -7.89987510e+03\n",
      " -2.67533162e+01  4.60310522e+01  4.15133238e+01 -1.41323309e+01\n",
      "  2.54862877e+01  1.69833986e+03 -2.55988175e+01 -7.22782077e+01\n",
      "  3.94238036e+02 -1.03341032e+03 -1.84686105e+01  2.09735758e+02\n",
      "  7.67172621e+01 -6.56419370e+01  1.00965725e+02 -1.14187926e+02\n",
      " -4.46094571e+01 -2.95428689e+01 -2.86963800e+01 -6.89913701e+02\n",
      "  5.79163753e+01  1.46018189e+01  2.76958183e+02 -8.03018264e+01\n",
      " -3.53667111e+02 -9.05768754e+01  3.64726624e+02  1.06025856e+02\n",
      " -7.38072421e+01  4.83040946e+01  9.84898050e+01  9.62128619e+01\n",
      " -4.17582644e+02  5.48840158e+01  5.73084654e+01  5.50918869e+00\n",
      " -3.33680779e+01 -1.89329588e+01 -2.07257657e+01  5.18967627e+01\n",
      " -4.20181680e+01  2.07832179e+02  5.16867335e+01 -6.07773350e+01\n",
      "  1.03619854e+02  1.12199258e+02 -2.93619972e+02  3.01803817e+01\n",
      "  2.36962496e+02  2.93469228e+01  5.58961943e+01  4.50794446e+01\n",
      " -2.97589424e+00 -3.75479977e+02 -5.84532473e+02  7.85408598e+01\n",
      " -2.87546345e+01 -5.50860980e+01  7.62732559e+01  5.22858819e+02\n",
      " -1.35185487e+02  2.94441218e+01 -1.19701527e+02 -2.65009016e+01\n",
      "  1.72723437e+01  2.36954039e+01  3.28853640e+01  9.51542913e+01\n",
      " -5.98710482e+01 -1.76638833e+01  1.30971661e+02  2.36103560e+02\n",
      "  1.11710551e+02 -4.33673390e+01 -3.20922492e+02 -9.52706556e+01\n",
      "  7.08217361e+01 -3.22931790e+01  3.13244014e+01  2.67248784e+02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data_test\n",
    "w, b, _ = svm_primal_model\n",
    "# y_pos \n",
    "\n",
    "x = 1 - b * (w)**-1\n",
    "print(x)\n",
    "w.T @ x.T + b >=  1\n",
    "# y_neg\n",
    "w.T @ x.T + b == - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Write code to find the support vectors from the dual problem solutions. Please copy the code snippet for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = linear space\n",
    "x = data_train\n",
    "w, b = get_primal_solution_from_dual(data_train, svm_dual_model)\n",
    "\n",
    "# y_pos \n",
    "w.T * x + b == 1\n",
    "# y_neg\n",
    "w.T * x + b == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Write code to choose C by using the validation set. Please copy the code snippet for the implementation. Report the test accuracy you get by using the optimal C found in the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_fit(x, y, w, b):\n",
    "    test_size = x.shape[0]\n",
    "    correct_predictions = 0\n",
    "    for i in range(test_size):\n",
    "        y_pred = np.sign(np.dot(x[i,:], w.T) + b)\n",
    "        if y_pred == y[i]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    return correct_predictions / test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of scikit learn svm model is 48.949999999999996 % with c value 2e-10\n",
      "accuracy of scikit learn svm model is 48.949999999999996 % with c value 2e-08\n",
      "accuracy of scikit learn svm model is 48.949999999999996 % with c value 2e-06\n",
      "accuracy of scikit learn svm model is 96.89999999999999 % with c value 0.0002\n",
      "accuracy of scikit learn svm model is 96.675 % with c value 0.02\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 2.0\n",
      "most optimal c is: 0.0002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nuse validation set\\ndata_validation\\nlabel_validation\\ntrain model\\nget accuracy\\nstore most accurate c '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_values = [2e-10, 2e-8, 2e-6, 2e-4, 2e-2, 2e0, 2e2, 2e4, 2e6,2e7,2e8,2e10]\n",
    "max_accuracy = 0\n",
    "optimal_c = 0\n",
    "\n",
    "# start by taking the first 8 values for now as computation time is too slow;\n",
    "for c in c_values[:6]:\n",
    "    clf = svm.SVC(C = c, kernel = 'linear')\n",
    "    clf.fit(data_validation, label_validation)\n",
    "    w = clf.coef_\n",
    "    b = clf.intercept_\n",
    "    svm_accuracy = test_model_fit(data_train, label_train, w, b)\n",
    "    if svm_accuracy > max_accuracy:\n",
    "        max_accuracy = svm_accuracy\n",
    "        optimal_c = c\n",
    "\n",
    "    print(\"accuracy of scikit learn svm model is\", svm_accuracy * 100, \"% with c value\", c)\n",
    "    \n",
    "print(\"most optimal c is:\", optimal_c)\n",
    "\n",
    "\"\"\"\n",
    "use validation set\n",
    "data_validation\n",
    "label_validation\n",
    "train model\n",
    "get accuracy\n",
    "store most accurate c \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of scikit learn svm model is 96.3 % with c value 2e-10\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 2e-08\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 2e-06\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 0.0002\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 0.02\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 2.0\n",
      "accuracy of scikit learn svm model is 96.3 % with c value 200.0\n",
      "most optimal c is: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# using primal form model\n",
    "for c in c_values[:7]:\n",
    "    svm_primal_model = svm_train_primal(data_train, label_train, 100)\n",
    "    svm_accuracy = test_model_fit(data_train, label_train, w, b)\n",
    "    if svm_accuracy > max_accuracy:\n",
    "        max_accuracy = svm_accuracy\n",
    "        optimal_c = c\n",
    "\n",
    "    print(\"accuracy of scikit learn svm model is\", svm_accuracy * 100, \"% with c value\", c)\n",
    "    \n",
    "print(\"most optimal c is:\", optimal_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b =  [0.63642135]\n",
      "Indices of support vectors =  [   0   28   43 ... 3993 3996 3998]\n",
      "Support vectors =  [[-0.36 -0.91 -0.99 ...  0.3   2.44 -1.26]\n",
      " [ 1.01 -1.13  1.49 ...  0.23 -0.3  -0.01]\n",
      " [ 1.02  2.08 -0.72 ...  1.84 -0.13  1.25]\n",
      " ...\n",
      " [ 1.77 -1.64  0.66 ...  0.7   0.16 -0.97]\n",
      " [-0.42 -2.15  1.14 ... -0.44 -0.09 -0.35]\n",
      " [ 0.4   0.16 -0.49 ...  0.89  0.21  1.09]]\n",
      "Number of support vectors for each class =  [754 760]\n",
      "Coefficients of the support vector in the decision function =  [[0.0002 0.0002 0.0002 ... 0.0002 0.0002 0.0002]]\n",
      "(1514, 200)\n"
     ]
    }
   ],
   "source": [
    "optimal_C = 0.0002\n",
    "# optimal_C = 100\n",
    "\n",
    "clf = svm.SVC(C = optimal_C, kernel = 'linear')\n",
    "clf.fit(data_train, label_train) # .fit(x, y)\n",
    "\n",
    "def show(clf):\n",
    "    # print('w = ',clf.coef_)\n",
    "    print('b = ',clf.intercept_)\n",
    "    print('Indices of support vectors = ', clf.support_)\n",
    "    # print(clf.support_.shape)\n",
    "    print('Support vectors = ', clf.support_vectors_)\n",
    "    print('Number of support vectors for each class = ', clf.n_support_)\n",
    "    print('Coefficients of the support vector in the decision function = ', np.abs(clf.dual_coef_))\n",
    "    print(clf.support_vectors_.shape)\n",
    "\n",
    "show(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of scikit learn svm model is 97.05 %\n"
     ]
    }
   ],
   "source": [
    "w = clf.coef_\n",
    "b = clf.intercept_\n",
    "svm_accuracy = test_model_fit(data_train, label_train, w, b)\n",
    "print(\"accuracy of scikit learn svm model is\", svm_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97e17e3a5115b3201813a983cb4b94900d2052584e97bfd9eeb6cc4985f4f43a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
